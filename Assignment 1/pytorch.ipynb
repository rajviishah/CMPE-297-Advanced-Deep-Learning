{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform= transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=64, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #input Image -28 * 28 * 1               \n",
    "        self.conv1=nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        #Size= (no. of out_channel-kernel_size+ 2*Padding/Stride) +1\n",
    "        #Size= (32-5+ 2*0/1 ) +1 = 24 * 24 * 32\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #Size= 12 * 12 * 32\n",
    "        self.conv2=nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5)\n",
    "        self.conv3=nn.Conv2d(in_channels=32,out_channels= 64, kernel_size=3)\n",
    "        self.fc1=nn.Linear(in_features=1*1*64, out_features=120)\n",
    "        self.fc2=nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3=nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        #Size =4 * 4 * 32\n",
    "        x=self.pool(F.relu(self.conv3(x))) \n",
    "        #Size =1 * 1 * 64\n",
    "        x = x.view(-1, 64 * 1 * 1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "       \n",
    "net=Net()\n",
    "net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for training using PyTorch 42.602737\n",
      "Eval accuracy using PyTorch is 100.00 and execution time 1.01 seconds\n"
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter()\n",
    "for epoch in range(2):\n",
    "    running_loss=0.0\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "        images, labels=data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward \n",
    "        outputs= net(images)\n",
    "        #calculate the loss between the target and the actuals\n",
    "        loss= criterion(outputs, labels)\n",
    "        #Gradient calculation uisng backward pass\n",
    "        loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "#calculate loss\n",
    "        running_loss+=loss.item()\n",
    "        if i%1875==1874:\n",
    "            print('epoch %d - image count %5d - Loss %.3f' % (epoch +1, i+1, running_loss/1875))      \n",
    "            running_loss = 0.0\n",
    "t1_end = perf_counter()\n",
    "print(\"Time for training using PyTorch %f\" %(t1_end-t1_start))\n",
    "\n",
    "\n",
    "#evaluate on test dataset\n",
    "correct=0\n",
    "total=0\n",
    "t1_start=perf_counter()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    '''Disabling gradient calculation is useful for inference, when you are sure that you will not call Tensor.backward(). \n",
    "    It will reduce memory consumption for computations that would otherwise have requires_grad=True.'''\n",
    "for  data in test_dataloader:\n",
    "        images. lables=data\n",
    "        outputs= net(images)\n",
    "        _,pred= torch.max(outputs,1)\n",
    "        total+=labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    \n",
    "t1_end=perf_counter()\n",
    "print(\"Eval accuracy using PyTorch is %.2f and execution time %.2f seconds\" %((100 * (correct / total)), (t1_end-t1_start)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
